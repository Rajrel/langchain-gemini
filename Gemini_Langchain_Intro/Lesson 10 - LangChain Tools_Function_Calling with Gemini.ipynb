{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ba9a76f-0b51-48b2-b748-2a8185a773b8",
   "metadata": {},
   "source": [
    "## Tool calling \n",
    "allows a model to respond to a given prompt by generating output that matches a user-defined schema. While the name implies that the model is performing some action, this is actually not the case! The model is coming up with the arguments to a tool, and actually running the tool (or not) is up to the user - for example, if you want to extract output matching some schema from unstructured text, you could give the model an \"extraction\" tool that takes parameters matching the desired schema, then treat the generated output as your final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0b8e8f1-ff7f-4c02-a6e4-30919742f37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Disable pip version check\n",
    "os.environ['PIP_DISABLE_PIP_VERSION_CHECK'] = '1'\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fc645048-9e7e-4b8d-b838-32a0b6edb6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, dotenv_values\n",
    "import google.generativeai as genai\n",
    "from IPython.display import Markdown, display\n",
    "import os \n",
    "\n",
    "load_dotenv()\n",
    "os.getenv(\"GOOGLE_API_KEY\") \n",
    "my_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "genai.configure(api_key=my_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efbfa384-d532-4927-bed8-6774522d5f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai.chat_models import  ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model= \"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff8c3777-c510-4437-bda3-4d80a5351f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "# Note that the docstrings here are crucial, as they will be passed along\n",
    "# to the model along with the class name.\n",
    "class add(BaseModel):\n",
    "    \"\"\"Add two integers together.\"\"\"\n",
    "\n",
    "    a: int = Field(..., description=\"First integer\")\n",
    "    b: int = Field(..., description=\"Second integer\")\n",
    "\n",
    "\n",
    "class multiply(BaseModel):\n",
    "    \"\"\"Multiply two integers together.\"\"\"\n",
    "\n",
    "    a: int = Field(..., description=\"First integer\")\n",
    "    b: int = Field(..., description=\"Second integer\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9f16cad-3a75-428d-b95b-f3588707c671",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools([multiply]) # parameter 'any for both' but currently not supported in Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31d30497-0622-4433-a6d6-f0048055ef2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'a': 3.0, 'b': 12.0},\n",
       "  'id': '0761ef6d-298b-4127-8289-7baf241a6a78'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is 3 * 12?\"\n",
    "\n",
    "llm_with_tools.invoke(query).tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d0608a5-8733-4c04-b155-bd377649427d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'add',\n",
       "  'args': {'a': 3.0, 'b': 12.0},\n",
       "  'id': '90148a9f-16b2-4470-bc50-86b99f7ab018'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "llm_with_tools = llm.bind_tools([add]) \n",
    "query = \"What is 3 + 12?\"\n",
    "\n",
    "llm_with_tools.invoke(query).tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "884b6eee-9d59-49d9-b760-b280240451c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add\n",
      "Adds a and b.\n",
      "\n",
      "    Args:\n",
      "        a: first int\n",
      "        b: second int\n",
      "{'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}\n"
     ]
    }
   ],
   "source": [
    "# Let's inspect some of the attributes associated with the tool.\n",
    "print(add.name)\n",
    "print(add.description)\n",
    "print(add.args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ca1b6b-5d9c-42a8-ba2c-92ad3f7252d3",
   "metadata": {},
   "source": [
    "##### Passing tool outputs to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db8f4669-387b-4d26-bb3d-d9be0a97805a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is 3 + 12?'),\n",
       " AIMessage(content='', additional_kwargs={'function_call': {'name': 'add', 'arguments': '{\"a\": 3.0, \"b\": 12.0}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-f7143260-f6f7-4f78-9142-2c5697b8b9c2-0', tool_calls=[{'name': 'add', 'args': {'a': 3.0, 'b': 12.0}, 'id': '1c86c68e-c4bb-467e-889c-a9f644c31970'}], usage_metadata={'input_tokens': 72, 'output_tokens': 19, 'total_tokens': 91}),\n",
       " ToolMessage(content='15', tool_call_id='1c86c68e-c4bb-467e-889c-a9f644c31970')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, ToolMessage\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "tools = [add]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "messages = [HumanMessage(query)]\n",
    "ai_msg = llm_with_tools.invoke(messages)\n",
    "messages.append(ai_msg)\n",
    "\n",
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\"add\": add}[tool_call[\"name\"].lower()]\n",
    "    tool_output = selected_tool.invoke(tool_call[\"args\"])\n",
    "    messages.append(ToolMessage(tool_output, tool_call_id=tool_call[\"id\"]))\n",
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ad93bae-805b-467d-b344-218e00140e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='15. \\n', response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-d493adf0-223a-4661-9fbd-464b7708aaaf-0', usage_metadata={'input_tokens': 107, 'output_tokens': 3, 'total_tokens': 110})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.invoke(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55d062ef-4afe-4aa9-bc2f-8b94ea1d56a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = llm_with_tools.invoke(messages)\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3907a9-9f66-4f1e-af4f-7812ff61714c",
   "metadata": {},
   "source": [
    "We can customize the tool name and JSON args by passing them into the tool decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "17c6010b-64cd-4d7d-bc34-045f0719b31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiplication-tool\n",
      "Multiply two numbers.\n",
      "{'a': {'title': 'A', 'description': 'first number', 'type': 'integer'}, 'b': {'title': 'B', 'description': 'second number', 'type': 'integer'}}\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "class CalculatorInput(BaseModel):\n",
    "    a: int = Field(description=\"first number\")\n",
    "    b: int = Field(description=\"second number\")\n",
    "\n",
    "\n",
    "@tool(\"multiplication-tool\", args_schema=CalculatorInput, return_direct=True)\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "# Let's inspect some of the attributes associated with the tool.\n",
    "print(multiply.name)\n",
    "print(multiply.description)\n",
    "print(multiply.args)\n",
    "print(multiply.return_direct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b46163-3525-42d0-82eb-38f4890b9117",
   "metadata": {},
   "source": [
    "##### StructuredTool\n",
    "The  <i>StrurcturedTool.from_function </i> class method provides a bit more configurability than the @tool decorator, without requiring much additional code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5e659575-0738-40ee-b8c4-cd994a146f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import StructuredTool\n",
    "\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "async def amultiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "calculator = StructuredTool.from_function(func=multiply, coroutine=amultiply)\n",
    "\n",
    "print(calculator.invoke({\"a\": 2, \"b\": 3}))\n",
    "print(await calculator.ainvoke({\"a\": 2, \"b\": 5}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "07c39b59-dd28-433b-82fe-406f723c89df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Calculator\n",
      "multiply numbers\n",
      "{'a': {'title': 'A', 'description': 'first number', 'type': 'integer'}, 'b': {'title': 'B', 'description': 'second number', 'type': 'integer'}}\n"
     ]
    }
   ],
   "source": [
    "class CalculatorInput(BaseModel):\n",
    "    a: int = Field(description=\"first number\")\n",
    "    b: int = Field(description=\"second number\")\n",
    "\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "calculator = StructuredTool.from_function(\n",
    "    func=multiply,\n",
    "    name=\"Calculator\",\n",
    "    description=\"multiply numbers\",\n",
    "    args_schema=CalculatorInput,\n",
    "    return_direct=True,\n",
    "    # coroutine= ... <- you can specify an async method if desired as well\n",
    ")\n",
    "\n",
    "print(calculator.invoke({\"a\": 2, \"b\": 3}))\n",
    "print(calculator.name)\n",
    "print(calculator.description)\n",
    "print(calculator.args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8bd391-166d-421f-8865-b8bf482c7396",
   "metadata": {},
   "source": [
    "##### Handling Tool Errors\n",
    "If you're using tools with agents, you will likely need an error handling strategy, so the agent can recover from the error and continue execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5e113bfc-167d-4d49-a0d1-291e1a61972a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import ToolException\n",
    "\n",
    "\n",
    "def get_weather(city: str) -> int:\n",
    "    \"\"\"Get weather for the given city.\"\"\"\n",
    "    raise ToolException(f\"Error: There is no city by the name of {city}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1f88a889-a04b-4dac-bfc9-5dacd300a809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Error: There is no city by the name of foobar.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_weather_tool = StructuredTool.from_function(\n",
    "    func=get_weather,\n",
    "    handle_tool_error=True,\n",
    ")\n",
    "\n",
    "get_weather_tool.invoke({\"city\": \"foobar\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4be132b6-b52f-4f5b-a3c4-b277cf5540e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling the error using a function:\n",
    "def _handle_error(error: ToolException) -> str:\n",
    "    return f\"The following errors occurred during tool execution: `{error.args[0]}`\"\n",
    "\n",
    "\n",
    "get_weather_tool = StructuredTool.from_function(\n",
    "    func=get_weather,\n",
    "    handle_tool_error=_handle_error,\n",
    ")\n",
    "\n",
    "get_weather_tool.invoke({\"city\": \"foobar\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dbcb06ad-af79-4afa-9977-b911fb367d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools([get_weather_tool])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f17e4cc6-c335-4ead-a45d-f9a145829e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'get_weather',\n",
       "  'args': {'city': 'richmond'},\n",
       "  'id': '8c2e44a6-8f5e-4e8a-a8f1-298e36a11066'}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is the weather of richmond?\"\n",
    "\n",
    "llm_with_tools.invoke(query).tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a86e4f9-3fa6-48c6-8cc2-7360d39a8c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
