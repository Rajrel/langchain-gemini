{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b10359d-c1e6-4e34-9adc-00c302feda81",
   "metadata": {},
   "source": [
    "How to move from legacy LangChain agents to more flexible LangGraph agents. LangChain agents (the AgentExecutor in particular) have multiple configuration parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c39b7a37-89e9-4831-bef6-3fc2501af96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, dotenv_values\n",
    "import google.generativeai as genai\n",
    "from IPython.display import Markdown, display\n",
    "import os \n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "os.getenv(\"GOOGLE_API_KEY\") \n",
    "my_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "genai.configure(api_key=my_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99008076-5acc-493c-a471-5928ecf8e6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai.chat_models import  ChatGoogleGenerativeAI\n",
    "model = ChatGoogleGenerativeAI(model= \"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a95bc329-8f31-4fcb-b72b-81a389839f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def magic_function(input: int) -> int:\n",
    "    \"\"\"Applies a magic function to an input.\"\"\"\n",
    "    return input + 2\n",
    "\n",
    "\n",
    "tools = [magic_function]\n",
    "\n",
    "\n",
    "query = \"what is the value of magic_function(3)?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca9e6291-e3d0-4c76-aa87-bbb45f2f98b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'what is the value of magic_function(3)?',\n",
       " 'output': 'The value of magic_function(3) is: `{\"output\": 5}`. \\n'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        # Placeholders fill up a **list** of messages\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "agent = create_tool_calling_agent(model, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools)\n",
    "\n",
    "agent_executor.invoke({\"input\": query})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cda1a5-2526-4a0a-8857-4f3e0bca6e62",
   "metadata": {},
   "source": [
    "LangGraph's react agent executor manages a state that is defined by a list of messages. It will continue to process the list until there are no tool calls in the agent's output. To kick it off, we input a list of messages. The output will contain the entire state of the graph-- in this case, the conversation history.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aab54728-20df-4305-b04f-c8b83bc055e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'what is the value of magic_function(3)?',\n",
       " 'output': 'The value of magic_function(3) is  `{\"output\": 5}`. \\n'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "app = create_react_agent(model, tools)\n",
    "\n",
    "\n",
    "messages = app.invoke({\"messages\": [(\"human\", query)]})\n",
    "{\n",
    "    \"input\": query,\n",
    "    \"output\": messages[\"messages\"][-1].content,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ce249ed-0438-4c96-8567-ce57a3374adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Pardon?',\n",
       " 'output': 'The `magic_function` applied to the input `3` returns a dictionary with a single key-value pair: `\"output\": 5`. \\n\\nIn other words, the function transforms the input `3` into the output value `5`. \\n'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_history = messages[\"messages\"]\n",
    "\n",
    "new_query = \"Pardon?\"\n",
    "\n",
    "messages = app.invoke({\"messages\": message_history + [(\"human\", new_query)]})\n",
    "{\n",
    "    \"input\": new_query,\n",
    "    \"output\": messages[\"messages\"][-1].content,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ee9671-2761-4409-9e34-719418b3560f",
   "metadata": {},
   "source": [
    "##### Prompt Templates\n",
    "With legacy LangChain agents you have to pass in a prompt template. You can use this to control the agent.\n",
    "\n",
    "With LangGraph react agent executor, by default there is no prompt. You can achieve similar control over the agent in a few ways:\n",
    "\n",
    "    Pass in a system message as input\n",
    "    Initialize the agent with a system message\n",
    "    Initialize the agent with a function to transform messages before passing to the model.\n",
    "\n",
    "LangGraph's prebuilt create_react_agent does not take a prompt template directly as a parameter, but instead takes a messages_modifier parameter. This modifies messages before they are passed into the model, and can be one of four values:\n",
    "\n",
    "    A SystemMessage, which is added to the beginning of the list of messages.\n",
    "    A string, which is converted to a SystemMessage and added to the beginning of the list of messages.\n",
    "    A Callable, which should take in a list of messages. The output is then passed to the language model.\n",
    "    Or a Runnable, which should should take in a list of messages. The output is then passed to the language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5f95dd0-54c5-43f7-94a2-d5f163eb930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "system_message = \"You are a helpful assistant. Respond only in English.\"\n",
    "# This could also be a SystemMessage object\n",
    "# system_message = SystemMessage(content=\"You are a helpful assistant. Respond only in Spanish.\")\n",
    "\n",
    "app = create_react_agent(model, tools, messages_modifier=system_message)\n",
    "messages = app.invoke({\"messages\": [(\"user\", query)]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e19cba2-c8d5-4846-ad06-44e767ac62f5",
   "metadata": {},
   "source": [
    "We can also pass in an arbitrary function. This function should take in a list of messages and output a list of messages. We can do all types of arbitrary formatting of messages here. In this cases, let's just add a SystemMessage to the start of the list of messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5bd40e36-7dfc-42f9-be2e-3acc51914aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'what is the value of magic_function(3)?', 'output': 'La valeur de magic_function(3) est  \"{\"output\": 5}\" . Bravo! \\n'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AnyMessage\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant. Respond only in French.\"),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def _modify_messages(messages: list[AnyMessage]):\n",
    "    return prompt.invoke({\"messages\": messages}).to_messages() + [\n",
    "        (\"user\", \"Also say 'Bravo!' after the answer.\")\n",
    "    ]\n",
    "\n",
    "\n",
    "app = create_react_agent(model, tools, messages_modifier=_modify_messages)\n",
    "\n",
    "\n",
    "messages = app.invoke({\"messages\": [(\"human\", query)]})\n",
    "print(\n",
    "    {\n",
    "        \"input\": query,\n",
    "        \"output\": messages[\"messages\"][-1].content,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb260e9-f139-4290-bfaa-579afa31d2f8",
   "metadata": {},
   "source": [
    "##### Memory\n",
    "    ###### In LangChain: \n",
    "    With LangChain's AgentExecutor, you could add chat Memory so it can engage in a multi-turn conversation.\n",
    "\n",
    "    ###### In LangGraph\n",
    "    Memory is just persistence, aka checkpointing.   \n",
    "    Add a checkpointer to the agent and you get chat memory for free.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "739782cf-d228-4e93-a9a9-09a2b5d9e866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output of magic_function(3) is:  {\"output\": 5} \n",
      "\n",
      "---\n",
      "Yes, I remember your name is Polly! ðŸ˜Š \n",
      "\n",
      "---\n",
      "The output of `magic_function(3)` was  `{\"output\": 5}`. \n",
      "\n",
      "Is there anything else I can help you with? \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from langgraph.checkpoint import MemorySaver  # an in-memory checkpointer\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "system_message = \"You are a helpful assistant.\"\n",
    "# This could also be a SystemMessage object\n",
    "# system_message = SystemMessage(content=\"You are a helpful assistant. Respond only in Spanish.\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = create_react_agent(\n",
    "    model, tools, messages_modifier=system_message, checkpointer=memory\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"test-thread\"}}\n",
    "print(\n",
    "    app.invoke(\n",
    "        {\n",
    "            \"messages\": [\n",
    "                (\"user\", \"Hi, I'm polly! What's the output of magic_function of 3?\")\n",
    "            ]\n",
    "        },\n",
    "        config,\n",
    "    )[\"messages\"][-1].content\n",
    ")\n",
    "print(\"---\")\n",
    "print(\n",
    "    app.invoke({\"messages\": [(\"user\", \"Remember my name?\")]}, config)[\"messages\"][\n",
    "        -1\n",
    "    ].content\n",
    ")\n",
    "print(\"---\")\n",
    "print(\n",
    "    app.invoke({\"messages\": [(\"user\", \"what was that output again?\")]}, config)[\n",
    "        \"messages\"\n",
    "    ][-1].content\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71ccc6d-f7ea-46b2-983c-5a7c3e07e424",
   "metadata": {},
   "source": [
    "##### Iterating through steps      \n",
    "\n",
    "With LangChain's AgentExecutor, you could iterate over the steps using the stream (or async astream) methods or the iter method. LangGraph supports stepwise iteration using stream        \n",
    "\n",
    "In LangGraph, things are handled natively using stream or the asynchronous astream method.        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c5c6377-d108-4a40-9b1b-3ee4bc1ba20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'function_call': {'name': 'magic_function', 'arguments': '{\"input\": 3.0}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-a3c90310-6f82-463e-a204-dfcbc4c8062a-0', tool_calls=[{'name': 'magic_function', 'args': {'input': 3.0}, 'id': '28fca33c-8eeb-42fb-b845-32468e200d79'}], usage_metadata={'input_tokens': 58, 'output_tokens': 15, 'total_tokens': 73})]}}\n",
      "{'tools': {'messages': [ToolMessage(content='5', name='magic_function', tool_call_id='28fca33c-8eeb-42fb-b845-32468e200d79')]}}\n",
      "{'agent': {'messages': [AIMessage(content='The value of magic_function(3) is: `{\"output\": 5}`. \\n', response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-120d7ea3-8a0c-48cc-a718-916d8f741208-0', usage_metadata={'input_tokens': 90, 'output_tokens': 19, 'total_tokens': 109})]}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AnyMessage\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def _modify_messages(messages: list[AnyMessage]):\n",
    "    return prompt.invoke({\"messages\": messages}).to_messages()\n",
    "\n",
    "\n",
    "app = create_react_agent(model, tools, messages_modifier=_modify_messages)\n",
    "\n",
    "\n",
    "for step in app.stream({\"messages\": [(\"human\", query)]}, stream_mode=\"updates\"):\n",
    "    print(step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3508ef3d-46cb-4ed1-9d2d-393a4b5122de",
   "metadata": {},
   "source": [
    "##### return_intermediate_steps\n",
    "In LangChain, setting this parameter on AgentExecutor allows users to access intermediate_steps, which pairs agent actions (e.g., tool invocations) with their outcomes.\n",
    "\n",
    "In LangGraph, By default the react agent executor in LangGraph appends all messages to the central state. Therefore, it is easy to see any intermediate steps by just looking at the full state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed117523-e558-456a-8615-e37a26d78b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what is the value of magic_function(3)?', id='c8c3772b-14e1-4176-b610-f9650fbd3451'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'magic_function', 'arguments': '{\"input\": 3.0}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-c719edd4-1af2-4689-b810-c9096150ff1b-0', tool_calls=[{'name': 'magic_function', 'args': {'input': 3.0}, 'id': '070c72d6-b7e7-453d-be21-d28f29d94af1'}], usage_metadata={'input_tokens': 52, 'output_tokens': 15, 'total_tokens': 67}),\n",
       "  ToolMessage(content='5', name='magic_function', id='a6e5e1ff-0ae3-4584-8153-ad5bc11ebdd1', tool_call_id='070c72d6-b7e7-453d-be21-d28f29d94af1'),\n",
       "  AIMessage(content='The value of magic_function(3) is `{\"output\": 5}`. \\n', response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-4d35920c-3697-400f-81e2-88a7cf2c2e32-0', usage_metadata={'input_tokens': 84, 'output_tokens': 18, 'total_tokens': 102})]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "app = create_react_agent(model, tools=tools)\n",
    "\n",
    "messages = app.invoke({\"messages\": [(\"human\", query)]})\n",
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032bebbc-973b-41c7-8f55-286fcf95aa73",
   "metadata": {},
   "source": [
    "##### max_iterations\n",
    "In LangChain, AgentExecutor implements a max_iterations parameter, allowing users to abort a run that exceeds a specified number of iterations.\n",
    "\n",
    "In LangGraph, this is controlled via recursion_limit configuration parameter.Note that in AgentExecutor, an \"iteration\" includes a full turn of tool invocation and execution. In LangGraph, each step contributes to the recursion limit, so we will need to multiply by two (and add one) to get equivalent results.\n",
    "\n",
    "If the recursion limit is reached, LangGraph raises a specific exception type, that we can catch and manage similarly to AgentExecutor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0382d1bb-9651-4673-91f2-42599ee727b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='what is the value of magic_function(3)?' id='e5ba1072-6774-4c57-a8cc-ea63ed1574dc'\n",
      "content='' additional_kwargs={'function_call': {'name': 'magic_function', 'arguments': '{\"input\": 3.0}'}} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]} id='run-36811a76-5b92-4998-ab88-72e283029d5e-0' tool_calls=[{'name': 'magic_function', 'args': {'input': 3.0}, 'id': '5a649215-e4a6-444e-98f4-534f216f9add'}] usage_metadata={'input_tokens': 52, 'output_tokens': 15, 'total_tokens': 67}\n",
      "content='5' name='magic_function' id='895034e9-8ff8-4572-8013-8aaca02d8b30' tool_call_id='5a649215-e4a6-444e-98f4-534f216f9add'\n",
      "content='The value of magic_function(3) is  `{\"output\": 5}`. \\n' response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]} id='run-49ec4b87-790f-4d88-b182-406edd9292a2-0' usage_metadata={'input_tokens': 84, 'output_tokens': 19, 'total_tokens': 103}\n"
     ]
    }
   ],
   "source": [
    "from langgraph.errors import GraphRecursionError\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "RECURSION_LIMIT = 2 * 3 + 1\n",
    "\n",
    "app = create_react_agent(model, tools=tools)\n",
    "\n",
    "try:\n",
    "    for chunk in app.stream(\n",
    "        {\"messages\": [(\"human\", query)]},\n",
    "        {\"recursion_limit\": RECURSION_LIMIT},\n",
    "        stream_mode=\"values\",\n",
    "    ):\n",
    "        print(chunk[\"messages\"][-1])\n",
    "except GraphRecursionError:\n",
    "    print({\"input\": query, \"output\": \"Agent stopped due to max iterations.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508dda75-64d5-47bf-93af-7fbf42427a94",
   "metadata": {},
   "source": [
    "##### max_execution_time\n",
    "In LangChain, AgentExecutor implements a max_execution_time parameter, allowing users to abort a run that exceeds a total time limit.\n",
    "\n",
    "In LangGraph\n",
    "With LangGraph's react agent, you can control timeouts on two levels.\n",
    "\n",
    "You can set a step_timeout to bound each step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "44fa1c34-f42d-49bb-a81b-7e23d740667b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'function_call': {'name': 'magic_function', 'arguments': '{\"input\": 3.0}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-da7414e4-50fe-49ed-8efa-835aba257012-0', tool_calls=[{'name': 'magic_function', 'args': {'input': 3.0}, 'id': '84aa6bd2-39f1-4097-abc5-b632555950ed'}], usage_metadata={'input_tokens': 52, 'output_tokens': 15, 'total_tokens': 67})]}}\n",
      "------\n",
      "{'tools': {'messages': [ToolMessage(content='5', name='magic_function', tool_call_id='84aa6bd2-39f1-4097-abc5-b632555950ed')]}}\n",
      "------\n",
      "{'agent': {'messages': [AIMessage(content='The value of magic_function(3) is  \\'{\"output\": 5}\\'. \\n', response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-06e74a96-845b-4ed5-8632-133cae6fc198-0', usage_metadata={'input_tokens': 84, 'output_tokens': 18, 'total_tokens': 102})]}}\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "app = create_react_agent(model, tools=tools)\n",
    "# Set the max timeout for each step here\n",
    "app.step_timeout = 2\n",
    "\n",
    "try:\n",
    "    for chunk in app.stream({\"messages\": [(\"human\", query)]}):\n",
    "        print(chunk)\n",
    "        print(\"------\")\n",
    "except TimeoutError:\n",
    "    print({\"input\": query, \"output\": \"Agent stopped due to max iterations.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dbad16-3d49-4865-944d-cbc255a62546",
   "metadata": {},
   "source": [
    "The other way to set a single max timeout for an entire run is to directly use the python stdlib asyncio library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b4ac8ae7-2879-41e7-99ce-5cf9ef561490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'function_call': {'name': 'magic_function', 'arguments': '{\"input\": 3.0}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-8add88cc-b1a4-44df-89b6-4386eb5dc4be-0', tool_calls=[{'name': 'magic_function', 'args': {'input': 3.0}, 'id': 'deb78b20-2d77-4e4b-b61b-6b081cd6c155'}], usage_metadata={'input_tokens': 52, 'output_tokens': 15, 'total_tokens': 67})]}}\n",
      "------\n",
      "{'tools': {'messages': [ToolMessage(content='5', name='magic_function', tool_call_id='deb78b20-2d77-4e4b-b61b-6b081cd6c155')]}}\n",
      "------\n",
      "{'agent': {'messages': [AIMessage(content='The value of magic_function(3) is: `{\"output\": 5}`. \\n', response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-6f3891b9-3a97-4a0e-8e3e-8d0621fae2a6-0', usage_metadata={'input_tokens': 84, 'output_tokens': 19, 'total_tokens': 103})]}}\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "app = create_react_agent(model, tools=tools)\n",
    "\n",
    "\n",
    "async def stream(app, inputs):\n",
    "    async for chunk in app.astream({\"messages\": [(\"human\", query)]}):\n",
    "        print(chunk)\n",
    "        print(\"------\")\n",
    "\n",
    "\n",
    "try:\n",
    "    task = asyncio.create_task(stream(app, {\"messages\": [(\"human\", query)]}))\n",
    "    await asyncio.wait_for(task, timeout=3)\n",
    "except TimeoutError:\n",
    "    print(\"Task Cancelled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a471b1-dc8c-4d83-a9e8-b2d589121163",
   "metadata": {},
   "source": [
    "##### Early_stopping_method\n",
    "In LangChain\n",
    "With LangChain's AgentExecutor, you could configure an early_stopping_method to either return a string saying \"Agent stopped due to iteration limit or time limit.\" (\"force\") or prompt the LLM a final time to respond (\"generate\").\n",
    "\n",
    "In LangGraph, you can explicitly handle the response behavior outside the agent, since the full state can be accessed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7ab25a5d-dcdc-427a-a34a-3737f4a3758d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='what is the value of magic_function(3)?' id='19ce4b7a-e7f6-4f81-b5f1-36b2a2241c29'\n",
      "content='' additional_kwargs={'function_call': {'name': 'magic_function', 'arguments': '{\"input\": 3.0}'}} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]} id='run-fe791725-f9a5-4933-88ff-dc1cf2478163-0' tool_calls=[{'name': 'magic_function', 'args': {'input': 3.0}, 'id': '521a39ef-3c12-4ed3-a6ba-592e965c7dd2'}] usage_metadata={'input_tokens': 52, 'output_tokens': 15, 'total_tokens': 67}\n",
      "content='5' name='magic_function' id='e8d353c8-d962-4776-b358-6d9a235881e1' tool_call_id='521a39ef-3c12-4ed3-a6ba-592e965c7dd2'\n",
      "content='The value of magic_function(3) is `{\"output\": 5}`. \\n' response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]} id='run-7db78a8c-4e38-4f1b-8cc8-639f0d40e25e-0' usage_metadata={'input_tokens': 84, 'output_tokens': 18, 'total_tokens': 102}\n",
      "{'input': 'what is the value of magic_function(3)?', 'output': 'Agent stopped due to max iterations.'}\n"
     ]
    }
   ],
   "source": [
    "from langgraph.errors import GraphRecursionError\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "RECURSION_LIMIT = 2 * 1 + 1\n",
    "\n",
    "app = create_react_agent(model, tools=tools)\n",
    "\n",
    "try:\n",
    "    for chunk in app.stream(\n",
    "        {\"messages\": [(\"human\", query)]},\n",
    "        {\"recursion_limit\": RECURSION_LIMIT},\n",
    "        stream_mode=\"values\",\n",
    "    ):\n",
    "        print(chunk[\"messages\"][-1])\n",
    "except GraphRecursionError:\n",
    "    print({\"input\": query, \"output\": \"Agent stopped due to max iterations.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c102c77-b353-4151-b98b-57cc9e5e52b8",
   "metadata": {},
   "source": [
    "##### trim_intermediate_steps\n",
    "With LangChain's AgentExecutor, you could trim the intermediate steps of long-running agents using trim_intermediate_steps, which is either an integer (indicating the agent should keep the last N steps) or a custom function.\n",
    "\n",
    "In LangGraph, We can use the messages_modifier just as before when passing in prompt templates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ddbe531e-8472-43bb-9cae-0ae3825628c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call number: 1\n",
      "Call number: 2\n",
      "Call number: 3\n",
      "Call number: 4\n",
      "Call number: 5\n",
      "Call number: 6\n",
      "Call number: 7\n",
      "Call number: 8\n",
      "Call number: 9\n",
      "Call number: 10\n",
      "Call number: 11\n",
      "Call number: 12\n",
      "Stopping agent prematurely due to triggering stop condition\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AnyMessage\n",
    "from langgraph.errors import GraphRecursionError\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "magic_step_num = 1\n",
    "\n",
    "\n",
    "@tool\n",
    "def magic_function(input: int) -> int:\n",
    "    \"\"\"Applies a magic function to an input.\"\"\"\n",
    "    global magic_step_num\n",
    "    print(f\"Call number: {magic_step_num}\")\n",
    "    magic_step_num += 1\n",
    "    return input + magic_step_num\n",
    "\n",
    "\n",
    "tools = [magic_function]\n",
    "\n",
    "\n",
    "def _modify_messages(messages: list[AnyMessage]):\n",
    "    # Give the agent amnesia, only keeping the original user query\n",
    "    return [(\"system\", \"You are a helpful assistant\"), messages[0]]\n",
    "\n",
    "\n",
    "app = create_react_agent(model, tools, messages_modifier=_modify_messages)\n",
    "\n",
    "try:\n",
    "    for step in app.stream({\"messages\": [(\"human\", query)]}, stream_mode=\"updates\"):\n",
    "        pass\n",
    "except GraphRecursionError as e:\n",
    "    print(\"Stopping agent prematurely due to triggering stop condition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b5f20a-d126-4ba8-8289-b6f2510bf021",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
