{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9144c874-9be3-473a-9f63-70fdfef88955",
   "metadata": {},
   "source": [
    "## Callbacks\n",
    "LangChain provides a callbacks system that allows you to hook into the various stages of your LLM application. This is useful for logging, monitoring, streaming, and other tasks.\n",
    "\n",
    "You can subscribe to these events by using the callbacks argument available throughout the API. This argument is list of handler objects, which are expected to implement one or more of the methods described below in more detail.\n",
    "\n",
    "Here is the information in tabular format:\n",
    "\n",
    "| Event               | Event Trigger                                      | Associated Method       |\n",
    "|---------------------|----------------------------------------------------|-------------------------|\n",
    "| Chat model start    | When a chat model starts                           | on_chat_model_start     |\n",
    "| LLM start           | When an llm starts                                 | on_llm_start            |\n",
    "| LLM new token       | When an llm OR chat model emits a new token        | on_llm_new_token        |\n",
    "| LLM ends            | When an llm OR chat model ends                     | on_llm_end              |\n",
    "| LLM errors          | When an llm OR chat model errors                   | on_llm_error            |\n",
    "| Chain start         | When a chain starts running                        | on_chain_start          |\n",
    "| Chain end           | When a chain ends                                  | on_chain_end            |\n",
    "| Chain error         | When a chain errors                                | on_chain_error          |\n",
    "| Tool start          | When a tool starts running                         | on_tool_start           |\n",
    "| Tool end            | When a tool ends                                   | on_tool_end             |\n",
    "| Tool error          | When a tool errors                                 | on_tool_error           |\n",
    "| Agent action        | When an agent takes an action                      | on_agent_action         |\n",
    "| Agent finish        | When an agent ends                                 | on_agent_finish         |\n",
    "| Retriever start     | When a retriever starts                            | on_retriever_start      |\n",
    "| Retriever end       | When a retriever ends                              | on_retriever_end        |\n",
    "| Retriever error     | When a retriever errors                            | on_retriever_error      |\n",
    "| Text                | When arbitrary text is run                         | on_text                 |\n",
    "| Retry               | When a retry event is run                          | on_retry                |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04eb1841-e00d-430d-98ee-5c3b7e1c6099",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, dotenv_values\n",
    "import google.generativeai as genai\n",
    "from IPython.display import Markdown, display\n",
    "import os \n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "os.getenv(\"GOOGLE_API_KEY\") \n",
    "my_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "genai.configure(api_key=my_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28114de4-93d8-4875-8b81-79a0f64c766c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai.chat_models import  ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model= \"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d109f04-8421-489e-bf86-708531f4697a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain RunnableSequence started\n",
      "Chain ChatPromptTemplate started\n",
      "Chain ended, outputs: messages=[HumanMessage(content='What is 1 + 2?')]\n",
      "Chat model started\n",
      "Chat model ended, response: generations=[[ChatGeneration(text='1 + 2 = 3 \\n', generation_info={'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, message=AIMessage(content='1 + 2 = 3 \\n', response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-69ea0e52-5de3-4bfc-aa0f-d24387d546cb-0', usage_metadata={'input_tokens': 9, 'output_tokens': 7, 'total_tokens': 16}))]] llm_output={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}} run=None\n",
      "Chain ended, outputs: content='1 + 2 = 3 \\n' response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]} id='run-69ea0e52-5de3-4bfc-aa0f-d24387d546cb-0' usage_metadata={'input_tokens': 9, 'output_tokens': 7, 'total_tokens': 16}\n"
     ]
    }
   ],
   "source": [
    "from typing import Any, Dict, List\n",
    "from langchain_core.callbacks import BaseCallbackHandler\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.outputs import LLMResult\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "class LoggingHandler(BaseCallbackHandler):\n",
    "    def on_chat_model_start(\n",
    "        self, serialized: Dict[str, Any], messages: List[List[BaseMessage]], **kwargs\n",
    "    ) -> None:\n",
    "        print(\"Chat model started\")\n",
    "\n",
    "    def on_llm_end(self, response: LLMResult, **kwargs) -> None:\n",
    "        print(f\"Chat model ended, response: {response}\")\n",
    "\n",
    "    def on_chain_start(\n",
    "        self, serialized: Dict[str, Any], inputs: Dict[str, Any], **kwargs\n",
    "    ) -> None:\n",
    "        print(f\"Chain {serialized.get('name')} started\")\n",
    "\n",
    "    def on_chain_end(self, outputs: Dict[str, Any], **kwargs) -> None:\n",
    "        print(f\"Chain ended, outputs: {outputs}\")\n",
    "\n",
    "\n",
    "callbacks = [LoggingHandler()]\n",
    "prompt = ChatPromptTemplate.from_template(\"What is 1 + {number}?\")\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "res = chain.invoke({\"number\": \"2\"}, config={\"callbacks\": callbacks})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3bd5e5-c376-4fc5-a2b0-300277bf2a08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
